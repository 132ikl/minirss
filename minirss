#!/usr/bin/env python3

from argparse import ArgumentDefaultsHelpFormatter, ArgumentParser
from dataclasses import dataclass
from hashlib import md5
from pathlib import Path
from shutil import which
from subprocess import run
from threading import Thread
from time import sleep

from appdirs import user_config_dir, user_data_dir
from feedparser import parse
from requests import get

parser = ArgumentParser(
    formatter_class=ArgumentDefaultsHelpFormatter,
)
parser.add_argument(
    "-l",
    "--list",
    help="path to list of feeds to check",
    type=str,
    default=user_config_dir() + "/minirss.cfg",
)
parser.add_argument(
    "-s",
    "--storage",
    help="path to storage file location",
    type=str,
    default=user_data_dir() + "/minirss-store.txt",
)
parser.add_argument(
    "-d",
    "--delay",
    help="delay in seconds between checking feeds",
    type=int,
    default=600,
)

# parse and validate args (check file perms)
args = parser.parse_args()
args.storage = Path(args.storage)
args.list = Path(args.list)
args.storage.touch()
args.list.touch()

# decide notification backend
if which("dunstify"):
    BACKEND = "dunstify"
elif which("notify-send"):
    BACKEND = "notify-send"
else:
    raise RuntimeError("Please install either notify-send or dunstify.")


@dataclass
class Feed:
    name: str
    url: str
    options: str = None


@dataclass
class Entry:
    title: str
    link: str
    feed: Feed

    def hash(self):
        return md5(f"{self.title} {self.link}".encode("utf-8")).hexdigest()

    @classmethod
    def from_raw(cls, raw, feed):
        link = None
        try:
            link = raw.links[0]["href"]
        except AttributeError:
            print(f"Failed to find link for {feed.name}")
        return cls(title=raw.title, link=link, feed=feed)


def notify(entry):
    cmd = [BACKEND, f"New post from {entry.feed.name}", entry.title]
    if BACKEND == "dunstify" and entry.link:
        cmd.append("--action=open,open")
        cmd.append("--timeout=0")
    process = run(cmd, capture_output=True, check=False)
    if "open" in process.stdout.decode("utf-8"):
        run(["xdg-open", entry.link], check=False)


def check_hashes(entries):
    # check which hashes are in storage
    # remove any of which are (ie. we've already notified for entry)
    with open(args.storage, "r") as file:
        text = file.read()

    output = []
    for entry in entries:
        if entry.hash() not in text:
            output.append(entry)
    return output


def grab_one(raw_entries, feed):
    try:
        raw_entry = raw_entries[0]
    except IndexError:
        print(f"Failed to find entries in feed {feed.name}")
    return Entry.from_raw(raw_entry, feed)


def main():
    with open(args.list, "r") as file:
        lines = file.read().splitlines()

    # Grab feeds
    feeds = []
    for line in lines:
        if line.startswith("#"):
            continue
        feeds.append(Feed(*line.split("|")))

    # Grab feed content
    entries = []
    for feed in feeds:
        raw = parse(get(feed.url).content).entries
        if feed.options and "fullhistory" in feed.options:
            entries += [Entry.from_raw(raw, feed) for raw in raw]
        else:
            entries.append(grab_one(raw, feed))

    # find new entries
    out = check_hashes(entries)

    # return early and avoid write i/o if no new entries
    if not out:
        return

    with open(args.storage, "r") as file:
        lines = file.read().splitlines()

    for entry in out:
        if entry.feed.options and "fullhistory" not in entry.feed.options:
            # remove old hash
            lines = [line for line in lines if not line.starts_with(entry.feed.name)]
        lines.append(f"{entry.feed.name}|{entry.hash()}")

        # run in separate thread so we don't wait forever on dunst action
        Thread(target=notify, args=(entry,), daemon=True).start()

    # write modified lines to file
    with open(args.storage, "w") as file:
        file.write("\n".join(lines))


while True:
    main()
    sleep(args.delay)
